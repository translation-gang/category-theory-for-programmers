\lettrine[lhang=0.17]{К}{атегория} — концепция на удивление простая.
Категория состоит из \newterm{объектов} и \newterm{стрелок}, идущих от одних объектов к другим.
Поэтому категории так легко представлять картинками. Объект можно изобразить кружочком или точкой,
а стрелка — она стрелка и есть. (Исключительно для разнообразия, я время от времени буду изображать
объекты в виде поросят, а стрелки — фейерверками.) Но сутью категории является \newterm{композиция}.
Ну или сутью композиции является категория — как вам больше нравится. Стрелки можно компоновать, так
что если у вас есть стрелка от объекта $A$ к объекту $B$, и вторая стрелка от объекта $B$ к объекту $C$,
то обязательно должна быть и ещё одна стрелка  --- их композиция --- идущая от $A$ к $C$.

\begin{figure}
\centering
\includegraphics[width=\textwidth]{images/img_1330.jpg}
\caption{В категории, если есть стрелка от $A$ к $B$ и стрелка от $B$ к $C$, то обязательно должна быть и стрелка,
соединяющая $A$ и $C$ напрямую — их композиция. Представленная диаграмма — ещё не категория, так как ей не хватает
тождественных морфизмом (см. далее).}

\section{Стрелки как функции}\label{стрелки-как-функции}

Не многовато ли уже абстрактной чуши? Не отчаивайтесь. Давайте поговорим о конкретных вещах.
Думайте о стрелках, которые ещё называются \newterm{морфизмами}, как о функциях.
У вас есть функция \code{f}, которая принимает аргумент типа $A$, и возвращает аргумент типа $B$.
Есть другая функция \code{g}, принимающая $B$, и возвращающая $C$. Их можно скомпоновать, попросту
передав результат $f$ в $g$. Таким образом мы определим новую функцию, принимающую $A$ и возвращающую $C$.

В математике такая композиция обозначается маленькой точкой между функциями: \ensuremath{g \circ f}.
Обратите внимание на порядок записи: функции записаны справа налево. Некоторых это может смутить. Возможно, вы знакомы
с нотацией каналов в Unix:

\begin{Verbatim}
lsof | grep Chrome
\end{Verbatim}
или с шевроном \code{>>} в F\# —-- оба записываются слева направо.
Но в математике и в Haskell функции компонуются справа налево.
Полезно читать \(g \circ f\) как ``g \emph{после} f.''

Давайте сделаем всё ещё более явным, написав немного кода на C. У нас есть одна
функция \code{f}, принимающая аргумент типа \code{A} и возвращающая значение типа \code{B}:

\begin{Verbatim}
B f(A a);
\end{Verbatim}
и другая:

\begin{Verbatim}
C g(B b);
\end{Verbatim}
Их композицией будет:

\begin{Verbatim}
C g_after_f(A a)
{
    return g(f(a));
}
\end{Verbatim}
Здесь снова мы видим запись композиции справа налево: \code{g(f(a))}; на этот раз на языке C.

Хотел бы я вам сказатЬ6 что в Стандартной Библиотеке C++ есть шаблон,
который принимает две функции и возвращает их композицию, но увы --- его нет.
Давайте для разнообразия попробуем Haskell. Вот определение функции из A в B:

\begin{Verbatim}
f :: A -> B
\end{Verbatim}
Аналогично:

\begin{Verbatim}
g :: B -> C
\end{Verbatim}
И их композиция:

\begin{Verbatim}
g . f
\end{Verbatim}
После того как увидишь, насколько просто некоторые вещи делаются в Haskell,
невозможность выразить простейшие функциональные концепции в C++ начинает немного напрягать.
В действительности, Haskell позволяет ещё и символы Unicode в коде использовать, так что
композицию можно записать и так:

\begin{Verbatim}
g ◦ f
\end{Verbatim}
Можно даже двойные двоеточия и стрелочки использовать:

\begin{Verbatim}[commandchars=\\\{\}]
f \ensuremath{\Colon} A → B
\end{Verbatim}
Итак, первый урок Haskell: двоёное двоеточие обозначает ``имеет тип\ldots{}''
Функциональный тип создаётся помещением стрелки между двумя типами. Композиция функций
производится вставкой точки (или Unicode-кружочка) между ними.

\section{Properties of Composition}\label{properties-of-composition}

There are two extremely important properties that the composition in any
category must satisfy.

\begin{enumerate}
\item
Composition is associative. If you have three morphisms, $f$, $g$, and $h$,
that can be composed (that is, their objects match end-to-end), you
don't need parentheses to compose them. In math notation this is
expressed as:
\[h\circ{}(g\circ{}f) = (h\circ{}g)\circ{}f = h\circ{}g\circ{}f\]
In (pseudo) Haskell:

\begin{Verbatim}
f :: A -> B
g :: B -> C
h :: C -> D
h . (g . f) == (h . g) . f == h . g . f
\end{Verbatim}
(I said ``pseudo,'' because equality is not defined for functions.)

Associativity is pretty obvious when dealing with functions, but it may
be not as obvious in other categories.

\item
For every object $A$ there is an arrow which is a unit of composition.
This arrow loops from the object to itself. Being a unit of composition
means that, when composed with any arrow that either starts at $A$ or ends
at $A$, respectively, it gives back the same arrow. The unit arrow for
object A is called $\idarrow[A]$ (\newterm{identity} on $A$). In math
notation, if \code{f} goes from $A$ to $B$ then
\[f \circ \idarrow[A] = f\]
and
\[\idarrow[B] \circ f = f\]
\end{enumerate}
When dealing with functions, the identity arrow is implemented as the
identity function that just returns back its argument. The
implementation is the same for every type, which means this function is
universally polymorphic. In C++ we could define it as a template:

\begin{Verbatim}
template<class T> T id(T x) { return x; }
\end{Verbatim}
Of course, in C++ nothing is that simple, because you have to take into
account not only what you're passing but also how (that is, by value, by
reference, by const reference, by move, and so on).

In Haskell, the identity function is part of the standard library
(called Prelude). Here's its declaration and definition:

\begin{Verbatim}
id :: a -> a
id x = x
\end{Verbatim}
As you can see, polymorphic functions in Haskell are a piece of cake. In
the declaration, you just replace the type with a type variable. Here's
the trick: names of concrete types always start with a capital letter,
names of type variables start with a lowercase letter. So here
\code{a} stands for all types.

Haskell function definitions consist of the name of the function
followed by formal parameters --- here just one, \code{x}. The body of
the function follows the equal sign. This terseness is often shocking to
newcomers but you will quickly see that it makes perfect sense. Function
definition and function call are the bread and butter of functional
programming so their syntax is reduced to the bare minimum. Not only are
there no parentheses around the argument list but there are no commas
between arguments (you'll see that later, when we define functions of
multiple arguments).

The body of a function is always an expression --- there are no
statements in functions. The result of a function is this expression ---
here, just \code{x}.

This concludes our second Haskell lesson.

The identity conditions can be written (again, in pseudo-Haskell) as:

\begin{Verbatim}
f . id == f
id . f == f
\end{Verbatim}
You might be asking yourself the question: Why would anyone bother with
the identity function --- a function that does nothing? Then again, why
do we bother with the number zero? Zero is a symbol for nothing. Ancient
Romans had a number system without a zero and they were able to build
excellent roads and aqueducts, some of which survive to this day.

Neutral values like zero or \code{id} are extremely useful when
working with symbolic variables. That's why Romans were not very good at
algebra, whereas the Arabs and the Persians, who were familiar with the
concept of zero, were. So the identity function becomes very handy as an
argument to, or a return from, a higher-order function. Higher order
functions are what make symbolic manipulation of functions possible.
They are the algebra of functions.

To summarize: A category consists of objects and arrows (morphisms).
Arrows can be composed, and the composition is associative. Every object
has an identity arrow that serves as a unit under composition.

\section{Composition is the Essence of
Programming}\label{composition-is-the-essence-of-programming}

Functional programmers have a peculiar way of approaching problems. They
start by asking very Zen-like questions. For instance, when designing an
interactive program, they would ask: What is interaction? When
implementing Conway's Game of Life, they would probably ponder about the
meaning of life. In this spirit, I'm going to ask: What is programming?
At the most basic level, programming is about telling the computer what
to do. ``Take the contents of memory address x and add it to the
contents of the register EAX.'' But even when we program in assembly,
the instructions we give the computer are an expression of something
more meaningful. We are solving a non-trivial problem (if it were
trivial, we wouldn't need the help of the computer). And how do we solve
problems? We decompose bigger problems into smaller problems. If the
smaller problems are still too big, we decompose them further, and so
on. Finally, we write code that solves all the small problems. And then
comes the essence of programming: we compose those pieces of code to
create solutions to larger problems. Decomposition wouldn't make sense
if we weren't able to put the pieces back together.

This process of hierarchical decomposition and recomposition is not
imposed on us by computers. It reflects the limitations of the human
mind. Our brains can only deal with a small number of concepts at a
time. One of the most cited papers in psychology,
\href{http://en.wikipedia.org/wiki/The_Magical_Number_Seven,_Plus_or_Minus_Two}{The
Magical Number Seven, Plus or Minus Two}, postulated that we can only
keep $7 \pm 2$ ``chunks'' of information in our minds. The details of our
understanding of the human short-term memory might be changing, but we
know for sure that it's limited. The bottom line is that we are unable
to deal with the soup of objects or the spaghetti of code. We need
structure not because well-structured programs are pleasant to look at,
but because otherwise our brains can't process them efficiently. We
often describe some piece of code as elegant or beautiful, but what we
really mean is that it's easy to process by our limited human minds.
Elegant code creates chunks that are just the right size and come in
just the right number for our mental digestive system to assimilate
them.

So what are the right chunks for the composition of programs? Their
surface area has to increase slower than their volume. (I like this
analogy because of the intuition that the surface area of a geometric
object grows with the square of its size --- slower than the volume,
which grows with the cube of its size.) The surface area is the
information we need in order to compose chunks. The volume is the
information we need in order to implement them. The idea is that, once a
chunk is implemented, we can forget about the details of its
implementation and concentrate on how it interacts with other chunks. In
object-oriented programming, the surface is the class declaration of the
object, or its abstract interface. In functional programming, it's the
declaration of a function. (I'm simplifying things a bit, but that's the
gist of it.)

Category theory is extreme in the sense that it actively discourages us
from looking inside the objects. An object in category theory is an
abstract nebulous entity. All you can ever know about it is how it
relates to other objects --- how it connects with them using arrows. This
is how internet search engines rank web sites by analyzing incoming and
outgoing links (except when they cheat). In object-oriented programming,
an idealized object is only visible through its abstract interface (pure
surface, no volume), with methods playing the role of arrows. The moment
you have to dig into the implementation of the object in order to
understand how to compose it with other objects, you've lost the
advantages of your programming paradigm.

\section{Challenges}\label{challenges}

\begin{enumerate}
\tightlist
\item
  Implement, as best as you can, the identity function in your favorite
  language (or the second favorite, if your favorite language happens to
  be Haskell).
\item
  Implement the composition function in your favorite language. It takes
  two functions as arguments and returns a function that is their
  composition.
\item
  Write a program that tries to test that your composition function
  respects identity.
\item
  Is the world-wide web a category in any sense? Are links morphisms?
\item
  Is Facebook a category, with people as objects and friendships as
  morphisms?
\item
  When is a directed graph a category?
\end{enumerate}
